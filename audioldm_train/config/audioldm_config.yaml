
model:
  vae:
    in_channels: 1
    out_channels: 1
    hidden_dim: 256
    latent_dim: 8
  
  diffusion:
    latent_dim: 8
    hidden_dim: 512
    time_embed_dim: 128
    text_embed_dim: 512
  
  clap:
    model_name: "laion/clap-htsat-unfused"  # Use actual CLAP model
    hidden_size: 1024
    embed_dim: 512

training:
  learning_rate: 1e-4
  weight_decay: 1e-6
  batch_size: 8
  max_epochs: 100
  num_workers: 4

data:
  sample_rate: 16000
  duration: 10.0
  metadata_path: "data/audiocaps/train.csv"
  audio_dir: "data/audiocaps/audio/"
  val_metadata_path: "data/audiocaps/val.csv"
  val_audio_dir: "data/audiocaps/audio/"

logging:
  log_dir: "logs/"
  save_top_k: 3
  monitor: "val_loss"